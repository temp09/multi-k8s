Hello, and welcome to capacity planning and scaling, adding a region. In this video, we'll explore adding a region to your Edge planet. We'll start with an overview and cover prerequisites, we'll describe a theoretical scenario, create a response files, and finally cover the actual process of adding the new region. The steps for adding a region are very similar to the individual steps to horizontally scale the planet one component at a time. During this video, we'll be emphasizing the process required to add the region, rather than the specific commands for adding each step. For detailed explanations of adding individual components, you can refer to other videos in this series. Alternatively, there is detailed documentation for adding an additional region at the link shown here. During this walkthrough, we extend an example by describing the prerequisites, processes, and considerations needed to successfully add new regions. Before starting planning for adding an additional region or regions, there are a number of prerequisites. When considering adding new regions, many of the design principles already discussed as part of topologies design apply. Before adding a new region you must produce a topology diagram that clearly describes all regions, both old and new present in the planet. Understand the basic principles governing data replication in Edge. And these include, multi-master replication for openLDAP, Cassandra ring topology requirements, every region takes Cassandra or viability zone must have an equal number of Cassandra nodes. Zookeeper cluster requirements, or zookeeper nodes across all regions are part of the same ensemble or cluster. The total number of voting nodes across the cluster must be odd. And PostgreSQL replication. The design or original topology may have had one or more PostgreSQL service, and a single master or master slave configuration. As part of the region expansion, it will be necessary to decide if new PostgreSQL servers will be required. You must also take into consideration the fact that adding a new region requires not only the addition of new components, but the reconfiguration of the existing components as well as updating server registrations. And finally, you need to ensure that the new topology complies with all cross-region component connectivity requirements. Documentation describing this can be found at the link shown onscreen. Now, we come onto describing our region addition scenario. Our scenario will illustrate the process of expanding our single region planet, this is our current topology by adding an additional region, target topology. The second region will have a similar configuration and an equal number of nodes. As you can see, the current topology has a single management server UI, an openLDAP server, Zookeeper and Cassandra clusters, both of which comprise three nodes. Three router message processor nodes. Two Qpid diamond and servers. And finally, a single PostgreSQL server and Edge PostgreSQL server. Onscreen now is the target topology or our desired state. We are using an equal number of nodes of the same type in our new region, region two. You can see here, there is required connectivity between openLDAP, the Zookeeper and Cassandra nodes, and PostgreSQL. As previously described by the Zookeeper and Cassandra, maintain a single cluster configuration across both regions. With our target topology defined, we can now create the new response files for expanding planets. Each region has a response file associated with it. Updated response files are required for both the new and also the existing region. If the original installation response file is available, it can be used as a base and modified to add references to, the openLDAP peer in region two, the new Zookeeper hosts in region two, and the new Cassandra hosts in region two. You can see these key variables and the samples onscreen now. Next, we will see the completed response files for both regions and talk about the changes. The first highlighted variable is MSIP. This always refers to the management server in the local region. Next we come to openLDAP variables. LDAP type is set to two in both regions, which infers a replicated setup. And a single region, this is set to one. LDAP SID is simply a unique identifier. This must be different in each region. An LDAP peer is the IP address of the remote peer to replicate with. Region one refers to region two and vice versa. The region variable sets an identifier for the region. We normally see DC one and DC two, but these could also be named. Zookeeper has two sets of variables per region. First is ZK hosts less all hosts in the ensemble. Notice the no designated DC2IP4 is listed as an observer in order to preserve an odd number of voting members. ZK client hosts, these are Zookeeper members for that region. Cassandra has a single variable describing its topology, but the value is different in each region. The variable should list hosts and its own region first, followed by the hosts and its peer regions. You can see this onscreen now. And finally, PostgreSQL. PG master and PG standby are self-explanatory and have the same value in each region. Once all components are set up, we will see how to set up PostgreSQL replication between the regions. A topology is finalized, a response files are being created, we can now go on to actually add the new region. When we're adding a new region, we actually start the process in the new region. Step one is to perform bootstrap an apigee-setup on all nodes in region two. Step two, we installed a new datastore nodes, Cassandra and Zookeeper in region two using the apigee-setup utility. Step three, with our new Cassandra and Zookeeper member nodes in place, we rerun setup on the datastore nodes in region one. And step four, our Zookeeper and Cassandra clusters have been expanded across the regions. So now, we run setup to reconfigure the management server in region one. As well as updating the management server with new server registrations, running setup also informs openLDAP that there is a new peer to replicate with. Step five is our Cassandra rebuild. On each node, node two rebuild is run passing DC one as a source region for streaming data. This step is both desk and network intensive. Step six, and still the new management server, UI an openLDAP. During this process, old data from openLDAP in region one will be copied and continuous replication initiated. Step seven, install the router and message processor nodes in region two. This can be done in parallel. Step eight, install the Qpid servers using the apigee-setup utility. These will be added to the analytics groups in a later step. Step nine, we installed a PostgreSQL and Postgres server. Step 10, at this stage our new region is almost complete. There are just a few steps that still need to be completed however. Region one contains the Postgres master and region two contains a standby server. First, we enable replication on the master as shown onscreen. We pass apigee PostgreSQL, setup replication of master, and a path to region one configuration file to the apigee service command. Next, we stop the new Postgres server in region two using apigee-service. Once the server is stopped, we delete all data we need opt, apigee data, apigee PostgreSQL directory. Finally, we configure the standby node again using the apigee-service command, but this time passing it the setup replication on standby option, and the region two configuration file. Step 11, next we update the analysis configuration. Edge uses analytics groups to map resources, keep it in Postgres to organizations and environments. You can see that we have two Postgres and four Qpid servers listed, and by the analytics and the consumer groups. Full documentation for this process can be found at docs.apigee.com. Step 12. After the process of expanding the Cassandra ring, the original members will be left with data they are no longer responsible for. This can be deleted by running nodetool on each host and adding the cleanup command. Step 13. If we need to support organizations across both regions, we need to run some reconfiguration. To do this, we run the apigee admin API command shown onscreen. Passing it the name of the organization we want to support across multiple regions, the name of the second region we created DC two, and the name of the gateway pod we specified in the region two response file, which is gateway two. The command is run on the management server and region one. Finally, we have the new message processors to each organization and environment. Again we use the apigee admin API command, passing it the organization name, the environment name, and UI idea of the new message processor. This needs to be repeated for each message processor in region two. At this point, our apigee Edge planet has been expanded from one to two regions. Proxies deployed in either region will be seamlessly deployed in all regions. To take advantage of this, a mechanism is required to route traffic to each data center. Most customers use global load balancers. It then just comes down to the customer to decide the load balancing strategy. Whether that be active/active, active/passive, geo-location, or some other routing rule. Any routing type is possible. Edge data across the planet remains active/active regardless of any traffic routing rules. This includes capacity planning and scaling, adding a region. For more information, you can visit docs.apigee.com. And to get involved in the community, please go to community.apigee.com. Thank you.