In this lab, you configured an HTTP Load Balancer with backends in US Central
one and Europe west one. Then you stress tested
the load balancer with a VM to demonstrate global load balancing
and auto-scaling. You can stay for a
lab walkthrough, but remember that GCP's
user interface can change, so your environment might
look slightly different. So here we are in the GCP console and the first thing
I'm going to do is configure the HTTP and
health check firewall rules. So let me go ahead and do that by navigating to VPC network, and specifically, firewall rules. So you will notice
that there are already some firewall rules
here for ICMP, internal RDP and SSH traffic. These are the ones
that always come with the default network. We're now going to create a
firewall rule to allow HTTP. So let me create firewall rule. I'm going to provide it a name. It's going to be for
the default network. I'm going to specify
the target tags by using HTTP server, and we'll have to define that target tag on
our instances later. The source, I'm going to set to IP ranges and just
set from anywhere. Then I can specify
the TCP port to 80. That's for HTTP. Then we can click "Create". Then we're going to create
a similar firewall rule for our health checkers. So I can do that while this
rule is being created. Again, on the same network, I'm going to use the
same target tags. So it just applies to
instances that have that tag. Now, for the IP ranges, I'm going to be a
lot more specific. These are provided in the
lab instructions for you, but these are the IP ranges
of the health checker. Now, when you enter those,
make sure you enter one first. You can click "Space" and you can see that it has
acknowledged that. Then you can copy and
paste the other IP range, and then click on
it, and you can see that it's grabbed that as well. Now, for the protocol and ports, in this case, we're just
going to specify all of TCP, but you could narrow that
down a little bit depending on what kind of health
check you're doing. So let me click "Create" on that. While these are being created, I can now create my custom image. So I'm going to go
to Compute Engine. We're going to create a VM. We're going to call
that a web server. I'm going to go
ahead and do that. I can leave the region
as US Central 1, zone, US Central 1-a. I'm going to now expand
this option down here, management, security, disks, networking, and sole tenancy. A couple of things I want
to do first under disks. I want to make sure
that this disk is not deleted when the
instance is deleted. That works because these
are just persistent disk, they are just network attached. On the networking, I'm going
to define the network tag, http-server, and this is going to be for our
default network. So that way, the
firewalls that we just created are going to be
applied to this instance. So let me go ahead
and click "Create." Once this instance
is up and running, we're going to customize it
by installing some software. So I'm going to just wait for
the instance to be created. There it is. I can click on SSH. I'm going to just
run the commands that are in the lab instructions. So first, I'm just going
to install Apache tube, and then I'm going to start
the Apache server after that. We're going to double-check
that server by navigating to the external IP
address that we have here, and that is why we attached that firewall rule
for the external IP. We don't really need the firewall rule for
the health checker yet, that is going to be later for
our backend instances and we haven't really configured that health check yet, anyway. So here we are, it's
still connecting, so let's just give it a couple
of seconds. There we are. I'm going to paste those
two commands in there. Let that run. Then I'm going to
start the service. So let me now go back to the console and click
on external IP. Here, we can see the Apache2
Debian Default Page. So we see that this has worked. Now, I want to set that
service to start on boot. So there's a command for that. So let me go back to my SSH terminal and
"paste" in that command. Now, I'm going to go
back to Compute Engine, and for the web server, I'm going to select reset. Yes, I want to make
sure I do that, so I'm going to click reset
on that confirmation. So this is now going to stop
and reboot the machine. I'll keep the same IP addresses and the same
persistent boot disk, but the memory is
essentially wiped. So therefore, the Apache services should be available
after the reset, and the update, our C-command
should've been successful. So we can wait for that. We have two options of
checking that status. We could navigate to the external IP address
or once it's back up, we could SSH back to the
instance and just run a command to check the status. It's telling me that the Apache service is actually running. So let's now prepare the disk, and we'll create a custom
image from that disk. So first, let's get out
of the SSH session. Let's verify one more time that the instance that we have
here has a disk associated, that that disk is not deleted
when I delete the instance. I can verify that by just clicking on the name
of the instance. Then I'm going to
scroll down to where it talks about my boot
disk, here it is. Under when deleting
instance, it says keep disk. If that was not the case, I could click "Edit" and I
could change that behavior. In our case, it's all
good, so I'm going to go ahead and "Delete" the instance. Here, it's asking me
would you also want to delete that disk which in our
case we're not going to do. So we are going to
delete the instance. If I go over here to disks, we can see that here we
have the disk itself. Now, we can go back to instances, we could wait for this to be deleted but the disk will remain. So really what we can do now is get on and create an image. So I'm going to click
on the image section. Here, we have the images
that are available. I'm going to create my custom
image, give it a name. My web server, we're going
to use as a source disk, but you can see there's some lots of other options like a snapshot, you could even do it
from another disk or a Cloud Storage file. So I'm going to do
that from the disk. We only have one disk available, so let's choose that. We can keep all the other
setting,s like the encryption, the location, and I
can click "Create". So this is now going to create
an image from that disk. At this point, we could even delete the disk itself
once that image has been created because we're actually being charged for
the disk while it's there. But for the purposes of the lab, we can leave that as all
your resources are being cleaned up in every Qwiklabs
project that you're using. So let's go ahead
and now configure the instance tab button and
create the instance groups. So I'm going to go
to Compute Engine, and we're going to go
to instance templates. We're going to create new
instance template and I'm going to give it a name,
mywebserver template. We're going to change the
machine type to a micro. We're just doing some various
small prototyping here. Now, the important thing
is I need to change the boot disk to select
my custom image. So I'm going to change that, go to a custom images, and here I have my web server
image from this project. If you have access
to other projects, you could also grab
an image from there. It's all set. I can choose the size as well of
the type of this. I'm just going to leave
those and click select. Now, I also need to make sure that I have the
right network tags. So let me go and expand the management security
and disruptions. By the way, you can see that this whole instance template
UI is very similar to the VM instance template because all you're
doing is you're just defining rules for
the VM instances, and once you could
groups from those, it will just use
all those settings. So under here, I'm going
to go to networking, pick the network, and I can then make sure that I
have the default network. Then I want to make
sure that I have my network tags so that
the firewall rules that we create in the beginning
are going to be applied to all the instances
created from this template. So let's go click Create, that really shouldn't take long. It's just going to
create a template not create any instances yet. Sometimes if I'm impatient, I'll just click refresh and we see we have
everything here. So now I can click on instance group and create
my instance group. So I'm going to start by creating instance group in us-central1, and this is going to
be a multi-zone or a regional across the
region us-central1. I could look into
the zones and maybe unselect certain zones or I select more zones
if I wanted to. This is going to be based on the template that
we just created. Now, the important piece is we're going to have some auto-scaling. So we're going to
have auto-scaling on. We're going to do that on the
HTTP load balanced usage. It's going to be import 80. We want a minimum of one
instance and maximum of five. We can leave the cool down period and you can hover over here to see that it just waits that much time before collecting
information. So we have some initialization this instance so you
want to make sure that it at least waits those 60 seconds before it
starts looking into that. Then we can also go
to health check. We don't have one yet
so we can go create a health check and we can just call it the HTTP
health check protocol. We could use HTTP or
leave it as TCP 80. What it's going to
do is it's going to check every 10 seconds. It's going to wait
five seconds between and if there are two
consecutive successes, means successful, three
consecutive failures means it have failure and means
it's unhealthy instance. So let me click save
and continue in that. Now this initial delay here this is for the boot
so we're going to set that to 60 seconds
for the health check, and then I'm going
to click create. Now, it's telling me that well, the auto-scaling isn't really
complete yet because we haven't set up the HTTP load
balancing, that's okay. We're about to do that. So let's just click okay. We're going to
repeat the same now for our instance group
in europe-west1. So let me grab that name. It's also going to
be a multi-zone. Obviously in this case, the region is europe-west1. Same instance template. Auto-scaling also
based on HTTP port 80, minimum one or maximum
five, cool down, and now we can just
select the health check. It seems like it doesn't
have that health check yet. That could actually
happen if you just go into this too fast. So let's actually click
cancel. Let's go back. Let's see if this instance
group has been created. Let's try that one more
time and see if we can get that health
check, and there it is. Okay, so we're just a little bit too fast so that could
certainly happen. Let me backtrack, put my
information back in here, multiple zones,
europe-west1, my template. I don't need to create one. I want to just select that HTTP maximum of five and set that initial
delay again to 60. We don't want to wait
this long for the lab. We're going to click Create
and it's again giving us the same warning
that we just saw. So we can just click okay. So here we can see the creation
of this instance group. We can also go to VM instances. We'll see that one of
the instance group has already created an instance. So you can see it starts
off with that name of the instance group and MIG by the way it's
what I put in here, that's short for
Managed Instance Group. We can see the Scaling
happening here. This one already
has one instance. This is Scaling from zero to one. You can actually
click in here and get a ton more information. If I go to monitoring, you'll see CPU usage,
details, members. It will show us that it's
scaling and how many it has. So you can get a lot
of information by either going into
the instance groups page or the VM instances. So either way, we have at least one instance
in each of the groups. So we are ready to now
configure the backends. So let's just verify
these actually. We can go to the navigation menu and VM
instance, we're already here. We could look into
these IP addresses. I can click on both of
these and we'll see that both of them have
the default page up. So that proves that the custom image that we created earlier is actually
being leveraged here. So we installed all
that custom software and our backend now has that. So let's configure the
HTTP load balancer. I'm going to go to
the navigation menu, network services, load balancing, create a load balancer. This is going to be an
HTTP load balancers. So to start that, I can choose if it's Internet-facing
or internal only. So from internet to my VMs, yes. Click Continue. I can give it
a name, HTTP load balancer. I'll start by
configuring the backend. I want to create a
backend service. I'm going to give it a name and I'm going to select
the instance groups. So let's start first with
us-central1, port number 80. The balancing mode
is going to be rate. Maximum of 50 requests per
second, capacity of 100. So just following the
lab instructions here. So it just means that that load balancer attempts to keep each of the instances that
will happen there at or below 50
requests per second. So I can click done and add another backend which is just
the only other one left. Let's hear for example, utilization at a CPU
utilization rate of 80 and a capacity of 100. So that's just going to mean
that disk configuration means that a load
balance attempts to keep each instance of europe-west1 at or below 80% CPU utilization. I can also attach this
in health check here, and then click create. Now, I could configure hosts and path rules that could define that certain traffic is being
sent to other backends depending on the
URL of the traffic. So video service could be sent to maybe a video backend versus static content to
a static backend. We're not leveraging that here. So let's move on to the
front end configuration. I could give it a
name but really I just need to specify
the protocol. The IP version, let's
just keep it ephemeral, port 80, click done, and we can review and finalize. So here we have our backend, our instances or I should
say our instance groups, as well as our front end. I could also add if I go
back here another front end. I've HTTP we could also add
IPV6, so let's do that. Now we can finalize that.
Now we have to front ends and we'll get
two IP addresses. So let's go ahead
and create that. Once that is up and running, we should be seeing
two addresses. The one in hexadecimal format is going to be our IPv6 address, and you're only going to be
able to navigate to that if your connection actually
allows it from where you are. Cell phones for example,
very often use IPv6, so you could maybe try to plug in the address
on your cell phone, and see if you're able to
access those backends. So let's wait for
that to load up. So if I click on
my load balancer, this is the front-end,
is just isn't ready yet. I went into here, but first, let's refresh and just wait
for that service to be ready, and then we can go in and get some more
information about it. So here I am, the load
balancer is not set up. I only took extra a
couple more seconds. So here we can see
the IP addresses. Again, this is the IPv4, this is the IPv6. So the first thing I could
do is I could actually just navigate to those
using my browser, because I did allow HTTP
traffic from anywhere. So let me just plug
that into my browser, and fast navigate to the IPv4. I'm actually getting a 404 error, and the lab manual
does talk about that. So let me also open another tab, and type in the IPv6 address, and run that, and it says it hasn't found
the service yet. So the lab manual does talk about the fact that
you could be getting a 404 or a 502 for awhile. So what you want to do here
is just refresh for awhile, and what you're really
doing is you're waiting for this configuration
to be applied to all of the Google front ends. So this is again, a global load balances has
to be applied everywhere. So the actual
implementation even though the console looks like
everything is ready, the service can sometimes take some time to actually
be reachable, and this can take a couple
minutes to be set up. So just dial refresh
a couple times, and let's wait for
that to come up. So here we are. I'm looking at the IPv4 address. I just refresh that
a couple times, and I can see the backend
which as we know, it should be the Apache2
Debian Default page, and I'm also navigating
to the IPv6 address. Actually I have
access to that here. So that is working
as well as expected. So now that we know that
the backend is working, it's time to stress test it. So what we're going to
do is we're going to create another instance now, and just generate a ton of
traffic to the load balancer, and then we're going to
monitor that traffic. So let me open up
another tab here, because I want to be
able to come back to the load balancer. I'm going to create another
instance now by going back to Compute Engine, and
create instance. I'm going to define a
name, just stress test. I'm going to put this in a
whole different region now. I'm going to select US West1. Now, in terms of my backends, I've a backend in US Central1 and a backend in Europe West1. The closest backend from this new instance
that I'm creating is going to be US Central1. So we would imagine
that traffic should be forwarded from US
West to US Central. That's going to be unless
the load is too high, and let's see if we can
actually break that and create a really high load, so that we also have
traffic that spills over into the Arab
region that we created. So I want to change
the boot disk. Here, let's actually select the custom image that
we already have. There is where we get a bunch
of software pre-installed. Then I'm just going
to go create that, and once that is up, I'm going to take the IP
address of our load balancer. I'm going to store that in
an environment variable. We'll verify it to make
sure that we have that, and then we're going
to place a load on it. So let's wait for that
instance to come up. With any new project, you always have a lot of information
on the right-hand side. That's useful to check
out if you're new to GCP. The instance is up. Let me go SSH, and let's store the IP address. Now, I need to grab that.
So let me go back here. We're going to use
the IPv4 address, and let me get my stress
test backup, and store that. That's also verify, make
sure this is stored, and here we can see it returning, and it matches that IP
address. That's great. Let's run a command to place
a load on our load balancer. Okay. So this uses Apache Bench, and it's not going
to benchmark this, and this is now going to
run in the background. So now what I can do is I can go back to my load balancer, which I'm looking at right now. If I'm looking at this
way, I can actually directly look at the backend, and click on HTTP backend, and we don't really
have any traffic yet. This takes take a little
while to update here. We can see the two
backends we have. We can see that one
is scaling on rate, one is scaling on
CPU utilization. Once we have a lot of traffic, it will start showing here where that traffic is coming from, and which instance
it is going to. So what we want to do
is just hang on here, and refresh this page
for a couple minutes, until we can actually see
some traffic being generated. So let me just go back
and go back in here, and no traffic yet. So lets just wait
a minute or two, and see what we can
visualize here. All right. So this only took a couple
of seconds. So here we are. We can see that there's a lot of traffic coming from
North America, that's for my stress tests, and we can see it's going both to US Central1 which is the closest, and that's where
most of our traffic is going, most of requests. But we also have some traffic
that is actually spilling over to our Europe
West1 instance. So we can see that we have
global load balancing here. What we could do now
is also we can monitor the backends to see if
they're actually scaling. So if I go to Compute
Engine and refresh, well, we can already see that we
have a bunch more backends now that are trying to handle all of the sudden
increase in traffic, and I really I'm stress
testing this quite a lot. If I go to instance groups, we can get more information here. It's saying that it's
already having issue with the amount of
instances I've selected, the maximum that is five. If we go in here into
the Europe West1, we can get more details
and monitoring. So it's showing us
how it scaled up, how it's managing the load
that's being placed on it. We could also look
in US Central1, and see that we now have
up to five instances already across different zones, and I can also go
into the monitoring here and get more information, and see that when we scaled up, and to refresh this a little bit, we'll see more instances in here, and I'll talk more about
the capacity it has. I can come back here, and now we can see that we have, because I really provided very minimal traffic
to your Central1, just 50 requests per second, but I'm making almost 281 here. So now we have a lot of
the traffic spilling over. So this is a really good
view to come back to, to always monitor
your load balancer. Mutually, you can also use Stackdriver logging
and monitoring, you set up alerts,
you set up roles. So maybe you need to increase that maximum
limit of five now. That's really a cost limit. You set that so that you don't
exceed your cost too much. But if you're saying, "Oh my God, I need to work on this traffic." You could have more instances. Maybe you're getting
an attack actually, at that point you could use
a product called Cloud AMR, to maybe allow and deny
certain IP addresses. But this is really all we want
it to achieve for the lab.