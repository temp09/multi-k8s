So far you've been creating GCP resources using the GCP
Console and Cloud Shell. I recommend the GCP
Console when you are new to using a service or
if you prefer a UI. Cloud Shell works best when
you are comfortable using a specific service
and you want to quickly create resources
using the command line. Deployment Manager takes
this one step further. Deployment Manager is an infrastructure
deployment service that automates the creation and management of GCP
resources for you. You just specify all the
resources needed for your application in
a declarative format and deploy your configuration. This deployment can be
repeated over and over with consistent results
and you can delete a whole deployment with
one command or click. The benefit of a
declarative approach is that it allows you to specify what the configuration should be and let the system figure
out the steps to take. Instead of deploying each
resource separately, you specify the set
of resources which compose the application
or service, allowing you to focus
on the application. Unlike Cloud Shell,
Deployment Manager will deploy resources
in parallel. You can even abstract parts
of your configuration into individual building
blocks or templates that can be used for
other configurations. Deployment Manager uses
the underlying APIs of each GCP service to
deploy your resources. This enables you to deploy almost everything we have
seen so far from instances, instance templates and
groups to VPC networks, firewall rules, VPN tunnels, Cloud routers, and
load balancers. For a full list of
supported resource types, see the link section
of this video. Before you get into the lab, let me walk you through
a quick example that shows how Deployment
Manager can be used to set up an auto mode network with
an HTTP firewall rule. I could put this whole deployment into one single configuration. However, it's useful to parameterize your
configuration with templates. Specifically, we're going
to create one template for the auto mode network and
one for the firewall rule. Therefore, if we want
to create either of these resources
somewhere else later on, we can use those templates. Let's start with the auto
mode network template which we can write
in Jinja2 or Python. Now, each resource must contain a name, type, and properties. For the name, I'm using an invariant variable
to get the name from the top-level configuration which makes this template
more flexible. For the type, I'm
defining the API for a VPC network which is
compute.v1.network. You can find all supported
types in the documentation or query them within Cloud Shell as you will explore
in the upcoming lab. By definition, an
auto mode network automatically creates a
subnetwork in each region. Therefore, I am setting the auto-create subnetworks
property to true. Next, let's write the template for the HTTP firewall rule. For the name, I'm again using an invariant variable to get the name from the
top-level configuration. For the type, I'm
defining the API for a firewall rule which
is compute.v1.firewall. The properties section
contains the network I want to apply this firewall rule
to the source IP ranges, and the protocols, and
ports that are allowed. Except for the source IP ranges, I'm defining these properties
as template properties. I will provide the
exact properties from the top-level configuration, which makes this firewall
rule extremely flexible. Essentially, I can use this
firewall rule template for any network and any
protocol and port combination. Next, let's write the top-level configuration
in YAML syntax. I start by importing the templates that I want to
use in this configuration, which are autonetwork.jinja
and firewall.jinja. Then I define the auto mode
network by giving it the name mynetwork and leveraging the
auto network.jinja template. I could create more
auto mode networks in this configuration with other names or simply reuse this template in other
configurations later on. Now I define the firewall
rule by giving it a name, leveraging the
firewall.jinja template, referencing my network, and defining the IP
protocol and port. I can easily add other
ports such as 443 for HTTPS or 22 for SSH traffic. Using the self link reference
for the network name ensures that the VPC network is created before the
firewalled rule. This is very important because
Deployment Manager creates all the resources in parallel
unless you use references. You would get an error without
the reference because you cannot create a firewall rule
for a non-existing network. Now there are other infrastructure
automation tools in addition to Deployment Manager
that you can use in GCP. You can also use Terraform, CHEF, Puppet, Ansible, or Packer. All of these tools allow you to treat your infrastructure
like software, which helps you decrease
costs, reduce risk, and deploy faster by capturing
infrastructure as code. You might recognize some of
these tools because they work across many Cloud
service providers. I recommend that you provision
and manage resources on Google Cloud with the
tools you already know. That's why in the upcoming lab, you'll have the choice of
using Deployment Manager or Terraform to automate the
deployment of Infrastructure. For more information on
each of these tools, see the link section
of this video.