Next, let's talk about internal load balancing. Internal load balancing is a regional, private load balancing service, for TCP and UDP paste traffic. In other words, this load balancer enables you to run and scale your services behind a private load balancing IP address. This means that it's only accessible through the internal IP addresses of virtual machine instances that are in the same region. Therefore, use internal load balancing to configure an internal load balancing IP address, to act as the front end to your private back end instances. Because you don't need a public IP for your load balanced service, your internal client requests stay internal to your VPC network and region. This often results in lower latency, because all your load balance traffic, will stay within Google's network, making your configuration much simpler. Let's talk more about the benefit of using a software defined internal load balanced service. GCP internal load balancing, is not based on a device or a VM instance. Instead, it is a software defined, fully distributed load balancing solution. In the traditional proxy model of internal load balancing, as shown on the left. You can figure an internal IP, on the load balancing device or instances and your client instances connect to this IP address. Traffic coming to the IP address is terminated at the load balancer, and the load balancer selects a backend to establish a new connection to. Essentially there are two connections. One between the client and the load balancer, and one between the load balancer and the backend. GCP internal load balancing distributes client instance requests to backends using a different approach, as shown on the right. It uses lightweight load balancing, built on top of Andromeda, which is Google's network virtualization stack, to provide software-defined load balancing that directly delivers a traffic from the client instance to a backend instance. To learn more about Andromeda, I recommend the blog post link below this video. Now, internal load balancing enables you to support use cases such as the traditional three-tier web services. In this example, the web tier, uses an external HTTPS load balancer, that provides a single global IP address, for users in San Francisco, Haiwai, Singapore and so on. The backends of this load balancer are located in the US-central1, and Asia-east1 regions, because this is a global load balancer. These backends can access an internal load balancer in each region as the application or internal tier. The backends of this internal tier, are located in US-central1-a, US-central1-b, and Asia-east1-a. The last tier is the database tier in each of those zones. The benefit of this three-tier approach, is that neither the database tier nor the application tier, is exposed externally. This simplifies security and network pricing.