Hello, and welcome to Edge Management Analytics. In this video, we'll give you an overview of analytics in Edge and talk about the analytics data flow, reporting, and finally, analytics groups and how to manage them. The analytics services offered by Edge give the business end-to-end visibility across the digital value chain. That provides unified operational, developer, application performance, and business metrics that allow you to monitor, measure, and manage your API program. Edge Analytic services offer end user-tailored and customizable dashboards and reports that use custom variables, dimensions, drill-downs, metric correlations and filters. For Deep-Dive into analytics reporting and the analytics API, we have a number of resources on our website. docs.apigee.com/analytics-services/content/analytics-dashbords explains the various reporting dashboards available at Edge covering topics from API proxy performance and business transactions to area code analysis and traffic composition. The second link covers all aspects of the Analytics API and how to use it to measure API performance. Before moving on to the Analytics walkthrough, It's worth taking a quick look at the API specifications and backend errors. As an operations professional, it is important to remember that when looking at Edge Analytics reports, two aspects are being represented, the target view and the proxy view. We can see in this example that the representation of the error is different in the proxy and the backend. The backend system returns a 200 okay with a payload containing the error message and an error code. Since this is a not found error message, the proxy itself returns a 404 to the calling API client. Understanding API specification error mapping is crucial for operations teams. The same differentiation should also be made between proxy performance, and target performance or execution time. Next, we going to walkthrough analytics on Edge. Analytics data is stored in a Postgres database. The actual stored data is partitioned by both organization and environment. If you look at the database schema, you would see a number of tables using the naming convention, organizationname.environmentname.fact. We'll see later how this partitioning allows easy scaling out of the Analytics components. To increase the performance of reports in the Enterprise UI, raw data is aggregated by another Apigee service. This aggregated data as presented in the Enterprise UI. Using either the management API or the enterprise UI, Raw data can also be queried using custom reports. It is important to understand the Analytics data flow. Apigee edge can be configured using two very different replication models. The default shown here is the master slave configuration. It is also possible to create an active/active set up using a publish subscribe method. During either of these flows, Analytics data is generated on the message processor and sent asynchronously to the Qpid Daemon. And in just process, the Qpid server component consumes the raw analytics data from Qpid and writes it into PostgresSQL. As previously mentioned, the data is partitioned logically by organization and environment. A separate Edge component, Postgres server, aggregates the data stored in PostgresSQL. When sizing Postgres machines, it's important to know that the general Analytics record size is around 2k. If custom variables are used, this record size will increase. All analytics components, Qpid Daemon, Qpid server, PostgresSQL and Postgres server are logically assigned to organizations and environments using analytics groups. The final topic for this lesson is Analytics Groups. Analytics Groups, axgroup, are data structures that describe the Qpid and Postgres servers associated to any given organization and environment. Looking at the example, we can see the API code to list Analytics Groups. This curl returns all of analytics groups present in the planet. We can see here that we have a single group named axgroup001. Looking further down, we can see that there was a single scope named traininglab~prod. This corresponds to an environment name prod in the training lab organization. Next, there are uuids for the Postgres and qpid-servers. The Postgres servers are colon separated, the qpid-servers are comma separated. Finally, we can see consumer groups which list the qpid-servers uuids as consumers, and the postgres server uuids as datastores. Most customers will never need to create new Analytics Groups. The exception to this, is if you are manually configuring groups, which is uncommon or horizontally scaling the analytics pipeline. Analysts groups are created by making API curls. The general format is you create a new group, you create a new consumer group within that axgroup, you set the consumer type and region. When updating the postgres master slave pair, the existing uuid should be removed before the new uuids are added. Again, this is done using API curls. The Qpid agent should be stopped before updating and analytics group and then restarted once the updates are completed. When horizontally scaling analytics groups, you may want to separate for one or more environments to a new analytics group. This is done by first creating the new analytics group. Next, the scope representing your organization and environment name is added to the new group using an API curl. Once this is confirmed, another API curl, the scope can be deleted from the current analytics group. This action usually requires a rolling restart of all the message processes serving traffic for that particular scope. This concludes this lesson. For more information, please browse our documentation at docs.apigee.com. And to get involved in the community, please visit community.apigee.com. Thank you.