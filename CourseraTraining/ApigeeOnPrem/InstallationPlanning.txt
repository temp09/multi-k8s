Hello. In this lesson, we are going to talk about Apigee installation planning. Putting time into the planning process is critical to success when performing your on-prem Apigee installation. The upfront investment pays for itself in time saved later in the installation process. Let's discuss the planning activities you will need to perform. Requirements analysis, installation topology design, organization design and capacity planning. The requirements analysis process provides a key input to the design of the installation topology. It drives many of the decisions you will make when determining how many hosts you will need and what their relationships will be. When analyzing your requirements, here are some important considerations. Is the planet intended for non-production or production use? How many regions comprise the planet? And how many can fail before peak API traffic is impacted? What are the average and peak loads you expect to experience? How large are your average request in response payloads? How complex do you expect your API proxies to be? How many hosts are you willing to lose in each region before a regional fail-over is necessary? How long do you need to retain detailed analytics data? And how many redundant management servers do you need? And do you need local management servers in some regions for performance reasons? Do you intend to use the developer portal? These questions can help you determine whether an architecture template is suitable for your environment or whether it is more appropriate to custom design your own installation topology. In the previous module, fundamentals, we discussed some common installation topologies that you can use as is or fine tuned to meet your needs. We learned that components can be added, removed or relocated to suit your performance and availability requirements. All of this can be done independently for various Apigee subsystems which include API traffic processing, system management, analytics and the developer portal. For some additional architecture templates, follow the links shown here. Keep in mind that for on-prem installation, you will likely need more than one Apigee planet to meet all of your non-production and production needs. In addition to supporting your non-production development needs, your full array of installed planets will need to support the needs of the operations team that needs to test changes and upgrades to both infrastructure and software. If development work requires access to a non-production planet with production like uptime guarantees, you may need a separate dedicated Apigee planet exclusively for infrastructure operations use. Another important consideration in your installation topology is network zoning. A common requirement driven by security or regulatory rules is to split your installation across one or more networks which are separated by network firewalls. As shown here, Apigee uses many TCP ports for internal and external communication. Increasing the number of network zones and your architecture, for instance a DMZ zone, an App zone and a database zone, will increase the complexity of the network firewall configuration required to support that architecture. There are additional ports needed in a multi-region architecture. Follow the link shown here to learn more. Try to minimize the number of network zones to keep installation and support of the system straight forward. It's ideal to pass requests through the DMZ directly using your load balance infrastructure rather than placing routers and message processors in a network zone separate from the other Apigee hosts. Once you have decided on an installation topology, you will need to determine the correct Apigee organization and environment configuration for that architecture. Recall from the fundamentals course that organizations allow you to create security boundaries between system users, and environments allow you to group and configure deployable resources. In addition, physical message processor capacity for handling API requests is allocated at the environment level. By default, all message processor capacity is shared across all environments. But you may wish to allocate dedicated capacity to one or more environments for security or performance reasons. A common mapping for on prime installations is to create a single organization named after your company, with environments used to represent various stages in your SDLC such as dev, test, QA, staging and production. The organization name stays constant across non-production and production planets and the environments are split across those planets as appropriate. Analyzing your requirements and determining your initial installation topology is the first step to successfully serving your API platform users. But you also need to think about the growth of your API program over time. Capacity planning should be an ongoing process and it starts before your initial installation takes place. Take care to build your installation topology in a flexible way which allows you to add additional processing capacity and redundancy as needed. Diligently track your infrastructure resource usage, as well as, your API traffic rate and size projections. Without those data you can become a victim of your own success, when your API programs suddenly draws unexpected traffic which impacts the platform's overall quality of service. We'll discuss capacity planning thoroughly in a later course. For more on this topic, refer to our documentation. If you have any questions, please post them to our community. Thanks for watching.