Build a Docker images:
----------------------  

mkdir test && cd test

1. create DockerFile :

 " cat > Dockerfile <<EOF
# Use an official Node runtime as the parent image
FROM node:6

# Set the working directory in the container to /app
WORKDIR /app

# Copy the current directory contents into the container at /app
ADD . /app

# Make the container's port 80 available to the outside world
EXPOSE 80

# Run app.js using node when the container launches
CMD ["node", "app.js"]
EOF "

2. write the node application:

" cat > app.js <<EOF
const http = require('http');

const hostname = '0.0.0.0';
const port = 80;

const server = http.createServer((req, res) => {
    res.statusCode = 200;
      res.setHeader('Content-Type', 'text/plain');
        res.end('Hello World\n');
});

server.listen(port, hostname, () => {
    console.log('Server running at http://%s:%s/', hostname, port);
});

process.on('SIGINT', function() {
    console.log('Caught interrupt signal and will exit');
    process.exit();
});
EOF " 


3. build image command:

   " docker build -t node-app:0.1 . "
   " docker images "


Run containers based on the image:
----------------------------------

  " docker run -p 4000:80 --name my-app node-app:0.1 " 
  
  ( The --name flag allows you to name the container if you like.
    The -p instructs Docker to map the host's port 4000 to the container's port 80.
	Now you can reach the server at http://localhost:4000. 
	Without port mapping, you would not be able to reach the container at localhost.)
	
Run the container images in backgroud:
--------------------------------------

  " docker run -p 4000:80 --name my-app -d node-app:0.1 "

docker ps
	
Test:
------

curl http://localhost:4000
Response:  Hello World



Debug :
---------

docker logs -f [container_id]

1. Use interactive shell to go to inside the container:

  " docker exec -it [container_id] bash "
  
2. Examine a container's metadata in Docker:

  " docker inspect CID "
  " docker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' CID "
  
  
Publish or push your images to container registry:
---------------------------------------------------

1. get the project ID : " gcloud config list project "

2. Tag your app : " docker tag node-app:0.1 gcr.io/my-k8-project-273116/node-app:0.1 " 

3. Push images to Registry: " docker push gcr.io/my-k8-project-273116/node-app:0.1 "


Stop and remove all containers:
-------------------------------

	docker stop $(docker ps -q)
	docker rm $(docker ps -aq)

1. Remove the child images:
   docker rmi node-app:0.1 gcr.io/my-k8-project-273116/node-app:0.1 node-app:0.1
   docker rmi node:6
   docker rmi $(docker images -aq) # remove remaining images
   docker images



Pull the image and run:
--------------------------

docker pull gcr.io/my-k8-project-273116/node-app:0.1

docker run -p 4000:80 --name my-app -d gcr.io/my-k8-project-273116/node-app:0.1

curl http://localhost:4000

docker pull gcr.io/google-samples/hello-app:1.0

docker run -p 4001:80 --name hello-app -d gcr.io/google-samples/hello-app:1.0

Deploy the app throiugh K8:
----------------------------

1. Setting a default compute zone:

    gcloud config set compute/zone us-central1-a
	
2.Creating a Kubernetes Engine cluster:

    gcloud container clusters create my-cluster
	
3.Get authentication credentials for the cluster:

   gcloud container clusters get-credentials my-cluster
   
4.Deploying an application to the cluster:

  a. Create a new deployment app-server from the image we build:
  
     kubectl create deployment my-node-app-server --image=gcr.io/my-k8-project-273116/node-app:0.1
	 
	 kubectl get deployments
	 
  b.create a Kubernetes Service, which is a Kubernetes resource that lets you expose your application to external traffic:
     
	 kubectl expose deployment my-node-app-server --type=LoadBalancer --port 80
	 
	 kubectl get service
	 
  c. Test :
     curl http://[EXTERNAL-IP]:8080
	 
5. Clean up the cluster:

    gcloud container clusters delete my-cluster